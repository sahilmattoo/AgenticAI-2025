{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d702244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "140aead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                         1.1.0\n",
      "langchain-classic                 1.0.0\n",
      "langchain-community               0.4.1\n",
      "langchain-core                    1.1.0\n",
      "langchain-groq                    1.1.0\n",
      "langchain-openai                  1.1.0\n",
      "langchain-text-splitters          1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep -i langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecefab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tavily import TavilyClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6f11c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily client initialized.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env (safe to call even if another cell calls it)\n",
    "load_dotenv()\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not TAVILY_API_KEY:\n",
    "    raise EnvironmentError(\"TAVILY_API_KEY not found. Add it to your .env or environment variables.\")\n",
    "\n",
    "# Initialize Tavily client (TavilyClient was imported in a previous cell)\n",
    "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "print(\"Tavily client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed3af8",
   "metadata": {},
   "source": [
    "## Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841ab488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def tavily_search(query: str) -> str:\n",
    "    \"\"\"Search the web using Tavily.\"\"\"\n",
    "    try:\n",
    "        response = tavily.search(query=query, max_results=5)\n",
    "        return str(response)\n",
    "    except Exception as e:\n",
    "        return f\"Tavily Error: {e}\"\n",
    "\n",
    "@tool\n",
    "def arxiv_search(query: str) -> str:\n",
    "    \"\"\"Search academic papers from arXiv based on a topic.\"\"\"\n",
    "    try:\n",
    "        url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results=3\"\n",
    "        res = requests.get(url).text\n",
    "        \n",
    "        # Extract VERY simply (beginner-friendly) titles\n",
    "        titles = []\n",
    "        for line in res.split(\"\\n\"):\n",
    "            if \"<title>\" in line and \"arXiv\" not in line:\n",
    "                title = line.replace(\"<title>\", \"\").replace(\"</title>\", \"\").strip()\n",
    "                titles.append(title)\n",
    "\n",
    "        return str(titles[:3])\n",
    "    except Exception as e:\n",
    "        return f\"ArXiv Error: {e}\"\n",
    "\n",
    "@tool\n",
    "def publications_search(topic: str) -> str:\n",
    "    \"\"\"Search academic publications using CrossRef API.\"\"\"\n",
    "    try:\n",
    "        url = f\"https://api.crossref.org/works?query={topic}&rows=3\"\n",
    "        res = requests.get(url).json()\n",
    "        items = res.get(\"message\", {}).get(\"items\", [])\n",
    "        papers = []\n",
    "        for item in items:\n",
    "            title = item.get(\"title\", [\"No title\"])[0]\n",
    "            year = item.get(\"created\", {}).get(\"date-parts\", [[None]])[0][0]\n",
    "            doi = item.get(\"DOI\", \"N/A\")\n",
    "            papers.append({\"title\": title, \"year\": year, \"doi\": doi})\n",
    "        return str(papers)\n",
    "    except Exception as e:\n",
    "        return f\"Publication Error: {e}\"\n",
    "\n",
    "@tool\n",
    "def evaluate_info(text: str) -> str:\n",
    "    \"\"\"Evaluate the quality of the research.\"\"\"\n",
    "    return f\"[Evaluation] Looks good. Helps support final report\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a49a5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_search, arxiv_search, publications_search, evaluate_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f4fe7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593a670",
   "metadata": {},
   "source": [
    "### Define Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f299131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(dict):\n",
    "    topic: str\n",
    "    plan: list\n",
    "    results: dict\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f7294",
   "metadata": {},
   "source": [
    "##### NODES (Planner â†’ Researcher â†’ Evaluator â†’ Reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eb9d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner(state: ResearchState):\n",
    "    \"\"\"LLM generates a multi-step research plan.\"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    prompt = f\"\"\"\n",
    "            Generate a simple 3â€“5 step research plan for topic: {topic}\n",
    "            Return steps as a numbered list.\n",
    "            \"\"\"\n",
    "    plan_text = llm.invoke(prompt).content\n",
    "    steps = [s.strip() for s in plan_text.split(\"\\n\") if s.strip()]\n",
    "\n",
    "    state[\"plan\"] = steps\n",
    "    state[\"results\"] = {}\n",
    "    return state\n",
    "\n",
    "def researcher(state: ResearchState):\n",
    "    \"\"\"Execute each plan step using Tavily, arXiv, CrossRef.\"\"\"\n",
    "    topic_results = {}\n",
    "\n",
    "    for step in state[\"plan\"]:\n",
    "        web = tavily_search.invoke(step)\n",
    "        arx = arxiv_search.invoke(step)\n",
    "        pub = publications_search.invoke(step)\n",
    "\n",
    "        topic_results[step] = {\n",
    "            \"web\": web,\n",
    "            \"arxiv\": arx,\n",
    "            \"crossref\": pub,\n",
    "        }\n",
    "\n",
    "    state[\"results\"] = topic_results\n",
    "    return state\n",
    "\n",
    "def evaluator(state: ResearchState):\n",
    "    \"\"\"Evaluate each step's results.\"\"\"\n",
    "    evals = {}\n",
    "\n",
    "    for step, content in state[\"results\"].items():\n",
    "        text = str(content)\n",
    "        evals[step] = evaluate_info.invoke(text)\n",
    "\n",
    "    state[\"evaluation\"] = evals\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def reporter(state: ResearchState):\n",
    "    \"\"\"LLM writes the final research report.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Write a structured research report based on the following:\n",
    "\n",
    "TOPIC:\n",
    "{state['topic']}\n",
    "\n",
    "PLAN:\n",
    "{state['plan']}\n",
    "\n",
    "RESEARCH RESULTS:\n",
    "{state['results']}\n",
    "\n",
    "EVALUATION:\n",
    "{state['evaluation']}\n",
    "\n",
    "Write it clearly with sections:\n",
    "- Overview  \n",
    "- Key Findings  \n",
    "- Academic References  \n",
    "- Insights  \n",
    "- Conclusion  \n",
    "\"\"\"\n",
    "\n",
    "    final = llm.invoke(prompt).content\n",
    "    state[\"summary\"] = final\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0a23e",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "880bb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ResearchState)\n",
    "\n",
    "graph.add_node(\"planner\", planner)\n",
    "graph.add_node(\"researcher\", researcher)\n",
    "graph.add_node(\"evaluator\", evaluator)\n",
    "graph.add_node(\"reporter\", reporter)\n",
    "\n",
    "graph.set_entry_point(\"planner\")\n",
    "graph.add_edge(\"planner\", \"researcher\")\n",
    "graph.add_edge(\"researcher\", \"evaluator\")\n",
    "graph.add_edge(\"evaluator\", \"reporter\")\n",
    "graph.add_edge(\"reporter\", END)\n",
    "\n",
    "research_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87ab7a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'evaluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention Mechanisms in Neural Networks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m research_agent\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: topic})\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“˜ FINAL MULTI-STEP RESEARCH REPORT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AAI/lib/python3.12/site-packages/langgraph/pregel/main.py:3068\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3065\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3066\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3069\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3070\u001b[0m     config,\n\u001b[1;32m   3071\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3075\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3076\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3077\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3078\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3079\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3081\u001b[0m ):\n\u001b[1;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AAI/lib/python3.12/site-packages/langgraph/pregel/main.py:2643\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2642\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2643\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2644\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2645\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2646\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2647\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2648\u001b[0m ):\n\u001b[1;32m   2649\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2651\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2652\u001b[0m     )\n\u001b[1;32m   2653\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AAI/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     run_with_retry(\n\u001b[1;32m    168\u001b[0m         t,\n\u001b[1;32m    169\u001b[0m         retry_policy,\n\u001b[1;32m    170\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    171\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    172\u001b[0m                 _call,\n\u001b[1;32m    173\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    174\u001b[0m                 retry_policy\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    175\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    176\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[1;32m    177\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    178\u001b[0m             ),\n\u001b[1;32m    179\u001b[0m         },\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AAI/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AAI/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AAI/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[34], line 61\u001b[0m, in \u001b[0;36mreporter\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreporter\u001b[39m(state: ResearchState):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"LLM writes the final research report.\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124mWrite a structured research report based on the following:\u001b[39m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124mTOPIC:\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124mPLAN:\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplan\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;124mRESEARCH RESULTS:\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124mEVALUATION:\u001b[39m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124mWrite it clearly with sections:\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124m- Overview  \u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124m- Key Findings  \u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124m- Academic References  \u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124m- Insights  \u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124m- Conclusion  \u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     final \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(prompt)\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     72\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m final\n",
      "\u001b[0;31mKeyError\u001b[0m: 'evaluation'",
      "\u001b[0mDuring task with name 'reporter' and id '2925046b-0c46-e27f-7114-ec82d1dee02d'"
     ]
    }
   ],
   "source": [
    "topic = \"Attention Mechanisms in Neural Networks\"\n",
    "\n",
    "output = research_agent.invoke({\"topic\": topic})\n",
    "\n",
    "print(\"\\n==========================================\")\n",
    "print(\"ðŸ“˜ FINAL MULTI-STEP RESEARCH REPORT\")\n",
    "print(\"==========================================\")\n",
    "print(output[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4562a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0363c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
