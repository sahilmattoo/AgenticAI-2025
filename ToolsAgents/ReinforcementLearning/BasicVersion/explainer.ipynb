{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb6a7c3",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook explains how an Agentic AI system executes step by step.\n",
    "\n",
    "We will explicitly see:\n",
    "- How policy is defined\n",
    "- How policy is injected into prompts using `partial`\n",
    "- How user input is applied later\n",
    "- How feedback changes policy\n",
    "- How the updated policy changes behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55af6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load .env (safe to call even if another cell calls it)\n",
    "load_dotenv()\n",
    "\n",
    "# main_safe.py\n",
    "from policy import ResponsePolicy\n",
    "from prompt import build_prompt\n",
    "from llm import llm, evaluator_llm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519eef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial policy: Policy(verbosity=medium, tone=neutral)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize Policy\n",
    "\n",
    "policy = ResponsePolicy()\n",
    "print(\"Initial policy:\", policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cdbb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={'verbosity': 'medium', 'tone': 'neutral'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tone', 'verbosity'], input_types={}, partial_variables={}, template='You are a helpful assistant.\\n\\nResponse rules:\\n- Verbosity: {verbosity}\\n- Tone: {tone}\\n\\nFollow these strictly.\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build prompt (LangChain ChatPromptTemplate.partial used elsewhere)\n",
    "prompt = build_prompt(policy)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1269d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "resp = chain.invoke(\"Explain Reinforcement Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c902ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[FALLBACK] Verbosity=medium, Tone=neutral -- RL is learning from rewards.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_text = f\"[FALLBACK] Verbosity={policy.verbosity}, Tone={policy.tone} -- RL is learning from rewards.\"\n",
    "agent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135b4612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reinforcement Learning (RL) is a subfield of machine learning where an agent learns to make decisions by interacting with an environment. The agent takes actions in the environment and receives feedback in the form of rewards or penalties, which it uses to learn optimal behaviors over time.\\n\\nThe key components of reinforcement learning include:\\n\\n1. **Agent**: The learner or decision maker that takes actions to achieve a goal.\\n2. **Environment**: The external system with which the agent interacts. The environment responds to the agent's actions.\\n3. **State**: A representation of the current situation in the environment, which the agent uses to decide on actions.\\n4. **Action**: A decision made by the agent that affects the state of the environment.\\n5. **Reward**: A numerical feedback signal received after taking an action, indicating the success of that action in achieving the desired goal.\\n\\nThe learning process typically involves exploring different actions to discover their effects and exploiting known actions that yield high rewards. This balance between exploration (trying new actions) and exploitation (choosing the best-known actions) is crucial for effective learning.\\n\\nReinforcement learning can be applied in various domains, such as robotics, game playing, and autonomous systems, where agents need to make sequential decisions based on the feedback they receive. Popular algorithms in reinforcement learning include Q-learning, deep Q-networks (DQN), and policy gradient methods.\\n\\nOverall, reinforcement learning enables agents to learn optimal policies that maximize their cumulative reward over time through trial and error.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_text = resp.content\n",
    "agent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18574337",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = \"This is too long. I just want crisp bullet points.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a097eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_interpreter import interpret_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb0f09f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall_sentiment': 'negative',\n",
       " 'dimensions': {'verbosity': 'decrease', 'tone': 'no_change'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpret_feedback(feedback,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cc1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe01432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"You are a policy evaluator.\n",
    "Return valid JSON with allowed fields:\n",
    "- verbosity: short | medium | detailed\n",
    "- tone: neutral | friendly | formal\n",
    "Return ONLY JSON.\"\"\"),\n",
    "    (\"human\", \"{feedback}\")\n",
    "])\n",
    "\n",
    "evaluator_chain = evaluator_prompt | evaluator_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9851b4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['feedback'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a policy evaluator.\\nReturn valid JSON with allowed fields:\\n- verbosity: short | medium | detailed\\n- tone: neutral | friendly | formal\\nReturn ONLY JSON.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['feedback'], input_types={}, partial_variables={}, template='{feedback}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x13679f5f0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x13679fce0>, root_client=<openai.OpenAI object at 0x135a65490>, root_async_client=<openai.AsyncOpenAI object at 0x13679f650>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), max_tokens=150)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86c7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_resp = evaluator_chain.invoke({\"feedback\": feedback})\n",
    "delta = json.loads(eval_resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36d37b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbosity': 'short', 'tone': 'neutral'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2c3fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy delta: {'verbosity': 'short', 'tone': 'neutral'}\n",
      "Updated policy: Policy(verbosity=short, tone=neutral)\n"
     ]
    }
   ],
   "source": [
    "print(\"Policy delta:\", delta)\n",
    "policy.update(delta)\n",
    "print(\"Updated policy:\", policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f2ea8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next interaction (shows adapted behavior)\n",
    "prompt = build_prompt(policy)\n",
    "chain = prompt | llm\n",
    "resp = chain.invoke(\"Explain Reinforcement Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee12d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinforcement Learning (RL) is a machine learning paradigm where an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards. The agent receives feedback in the form of rewards or penalties based on its actions and uses this feedback to improve its future decisions. Key components include:\n",
      "\n",
      "1. **Agent**: The learner or decision maker.\n",
      "2. **Environment**: The context in which the agent operates.\n",
      "3. **Actions**: Choices made by the agent.\n",
      "4. **States**: The current situation of the agent in the environment.\n",
      "5. **Rewards**: Feedback received after taking actions, guiding learning.\n",
      "\n",
      "The agent typically uses algorithms like Q-learning or policy gradients to learn optimal strategies over time.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0275e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
