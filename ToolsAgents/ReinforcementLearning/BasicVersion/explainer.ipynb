{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb6a7c3",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook explains how an Agentic AI system executes step by step.\n",
    "\n",
    "We will explicitly see:\n",
    "- How policy is defined\n",
    "- How policy is injected into prompts using `partial`\n",
    "- How user input is applied later\n",
    "- How feedback changes policy\n",
    "- How the updated policy changes behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55af6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load .env (safe to call even if another cell calls it)\n",
    "load_dotenv()\n",
    "\n",
    "# main_safe.py\n",
    "from policy import ResponsePolicy\n",
    "from prompt import build_prompt\n",
    "from llm import llm, evaluator_llm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519eef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial policy: Policy(verbosity=medium, tone=neutral)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize Policy\n",
    "\n",
    "policy = ResponsePolicy()\n",
    "print(\"Initial policy:\", policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cdbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt (LangChain ChatPromptTemplate.partial used elsewhere)\n",
    "prompt = build_prompt(policy)\n",
    "chain = prompt | llm\n",
    "resp = chain.invoke(\"Explain Reinforcement Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c902ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[FALLBACK] Verbosity=medium, Tone=neutral ##-- RL is learning from rewards.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_text = f\"[FALLBACK] Verbosity={policy.verbosity}, Tone={policy.tone} -- RL is learning from rewards.\"\n",
    "agent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135b4612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment. The goal of the agent is to maximize a cumulative reward through a process of trial and error. Here are the key components and concepts involved in reinforcement learning:\\n\\n1. **Agent and Environment**: The agent is the learner or decision-maker, while the environment is everything the agent interacts with. The agent takes actions in the environment and receives feedback in the form of rewards.\\n\\n2. **States and Actions**: The environment can be in various states, and the agent can take different actions. A state represents a specific configuration of the environment, while an action is a choice made by the agent that affects the state.\\n\\n3. **Reward**: After taking an action and transitioning to a new state, the agent receives a reward, which is a numerical value. This reward serves as feedback for the agent to evaluate the effectiveness of its action.\\n\\n4. **Policy**: The policy is a strategy used by the agent to determine which action to take in a given state. It can be deterministic or stochastic. The ultimate aim is to learn an optimal policy that maximizes the expected cumulative reward over time.\\n\\n5. **Value Function**: The value function estimates the expected return (cumulative future rewards) from a given state or state-action pair. It helps the agent evaluate the long-term potential of its actions.\\n\\n6. **Exploration vs. Exploitation**: The agent faces a trade-off between exploring new actions to discover their rewards and exploiting known actions that yield high rewards. Balancing this trade-off is crucial for effective learning.\\n\\n7. **Learning Algorithms**: Common algorithms in reinforcement learning include Q-learning, Deep Q-Networks (DQN), and various policy gradient methods. These algorithms help the agent update its policy or value function based on experiences gathered from interactions with the environment.\\n\\nReinforcement learning has applications in various fields, including robotics, game'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_text = resp.content\n",
    "agent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18574337",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = \"This is too long. I just want crisp bullet points.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe01432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"You are a policy evaluator.\n",
    "Return valid JSON with allowed fields:\n",
    "- verbosity: short | medium | detailed\n",
    "- tone: neutral | friendly | formal\n",
    "Return ONLY JSON.\"\"\"),\n",
    "    (\"human\", \"{feedback}\")\n",
    "])\n",
    "\n",
    "evaluator_chain = evaluator_prompt | evaluator_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86c7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_resp = evaluator_chain.invoke({\"feedback\": feedback})\n",
    "delta = json.loads(eval_resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36d37b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbosity': 'short', 'tone': 'neutral'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae2c3fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy delta: {'verbosity': 'short', 'tone': 'neutral'}\n",
      "Updated policy: Policy(verbosity=short, tone=neutral)\n"
     ]
    }
   ],
   "source": [
    "print(\"Policy delta:\", delta)\n",
    "policy.update(delta)\n",
    "print(\"Updated policy:\", policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2ea8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next interaction (shows adapted behavior)\n",
    "prompt = build_prompt(policy)\n",
    "chain = prompt | llm\n",
    "resp = chain.invoke(\"Explain Reinforcement Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee12d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards. The agent receives feedback in the form of rewards or penalties based on its actions. It uses this feedback to improve its strategy over time, typically through trial and error. Key concepts include states, actions, rewards, and policies. RL is widely used in robotics, game playing, and autonomous systems.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0275e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
