{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64b33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain langchain-openai langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0dd7b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1aabf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to stop\n",
      "\n",
      "AI: Hello! How can I assist you today?\n",
      "AI: I don't know your name unless you tell me. What would you like me to call you?\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ONE-SHOT CONVERSATIONAL AI\n",
    "# ===============================\n",
    "\n",
    "# pip install --upgrade langchain langchain-openai langchain-community\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# -------------------------------\n",
    "# 1. LLM\n",
    "# -------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Prompt with history\n",
    "# -------------------------------\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful conversational AI assistant.\"), # Sets personality & behavior\n",
    "    MessagesPlaceholder(variable_name=\"history\"), # Injects all past messages here\n",
    "    (\"human\", \"{input}\") # Current user message\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Session-based memory\n",
    "# -------------------------------\n",
    "store = {} # In-memory store for session histories\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "# RunnableWithMessageHistory is a Wrapper \n",
    "# Reads previous messages\n",
    "# Adds new messages after each turn\n",
    "# Manages the Session Internally \n",
    "\n",
    "# -------------------------------\n",
    "# 4. Run\n",
    "# -------------------------------\n",
    "session_id = \"test_user\"\n",
    "\n",
    "print(\"Type 'exit' to stop\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    response = conversation.invoke(\n",
    "        {\"input\": user_input},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    print(\"AI:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487c8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio\n",
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fa8342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "openAIkey = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openAIkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e53147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 22:36:53.404 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.406 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.472 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/agents/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2026-01-23 22:36:53.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.651 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.652 Session state does not function when running a script without `streamlit run`\n",
      "2026-01-23 22:36:53.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.655 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.656 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.656 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.656 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.658 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.658 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.660 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.660 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.660 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.661 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.661 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.661 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-23 22:36:53.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# STREAMLIT CHAT UI â€“ AGENT WITH TOOLS + MEMORY\n",
    "# =====================================================\n",
    "\n",
    "# pip install streamlit langchain langchain-openai langchain-community chromadb\n",
    "\n",
    "import uuid\n",
    "import streamlit as st\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# ---------------------------\n",
    "# Streamlit Page Config\n",
    "# ---------------------------\n",
    "st.set_page_config(page_title=\"Conversational AI with Memory\", layout=\"centered\")\n",
    "st.title(\"ðŸ¤– Conversational AI (Tools + Long-Term Memory)\")\n",
    "\n",
    "# ---------------------------\n",
    "# OpenAI Key\n",
    "# ---------------------------\n",
    "#OPENAI_API_KEY = st.secrets.get(OPENAI_API_KEY, OPENAI_API_KEY)\n",
    "OPENAI_API_KEY =  os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1. LLM\n",
    "# ---------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.2,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Long-Term Memory (Vector DB)\n",
    "# ---------------------------\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"long_term_memory\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./memory_db\"\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Tools\n",
    "# ---------------------------\n",
    "@tool\n",
    "def store_memory(info: str) -> str:\n",
    "    \"\"\"Store important personal information.\"\"\"\n",
    "    vectorstore.add_texts([info], ids=[str(uuid.uuid4())])\n",
    "    return \"Memory stored.\"\n",
    "\n",
    "@tool\n",
    "def retrieve_memory(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant personal memory.\"\"\"\n",
    "    results = vectorstore.similarity_search(query, k=2)\n",
    "    if not results:\n",
    "        return \"No memory found.\"\n",
    "    return \" | \".join(r.page_content for r in results)\n",
    "\n",
    "tools = {t.name: t for t in [store_memory, retrieve_memory]}\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Prompt\n",
    "# ---------------------------\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"You are a conversational AI assistant.\n",
    "     - Remember important user details.\n",
    "     - Use memory when answering personal questions.\n",
    "     - Do not greet unless the user greets first.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm.bind_tools(list(tools.values()))\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Session-based Memory\n",
    "# ---------------------------\n",
    "if \"session_id\" not in st.session_state:\n",
    "    st.session_state.session_id = \"streamlit_user\"\n",
    "\n",
    "if \"history_store\" not in st.session_state:\n",
    "    st.session_state.history_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in st.session_state.history_store:\n",
    "        st.session_state.history_store[session_id] = ChatMessageHistory()\n",
    "    return st.session_state.history_store[session_id]\n",
    "\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Chat History (UI)\n",
    "# ---------------------------\n",
    "if \"chat_ui\" not in st.session_state:\n",
    "    st.session_state.chat_ui = []\n",
    "\n",
    "# Render chat\n",
    "for role, message in st.session_state.chat_ui:\n",
    "    with st.chat_message(role):\n",
    "        st.markdown(message)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. User Input\n",
    "# ---------------------------\n",
    "user_input = st.chat_input(\"Type your message...\")\n",
    "\n",
    "if user_input:\n",
    "    # Show user message\n",
    "    st.session_state.chat_ui.append((\"user\", user_input))\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # Agent invocation\n",
    "    result = conversation.invoke(\n",
    "        {\"input\": user_input},\n",
    "        config={\"configurable\": {\"session_id\": st.session_state.session_id}}\n",
    "    )\n",
    "\n",
    "    # Handle tool calls\n",
    "    if result.tool_calls:\n",
    "        tool_messages = []\n",
    "\n",
    "        for call in result.tool_calls:\n",
    "            tool_fn = tools[call[\"name\"]]\n",
    "            tool_output = tool_fn.invoke(call[\"args\"])\n",
    "\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    tool_call_id=call[\"id\"],\n",
    "                    content=tool_output\n",
    "                )\n",
    "            )\n",
    "\n",
    "        final = conversation.invoke(\n",
    "            {\"input\": tool_messages},\n",
    "            config={\"configurable\": {\"session_id\": st.session_state.session_id}}\n",
    "        )\n",
    "\n",
    "        ai_response = final.content\n",
    "    else:\n",
    "        ai_response = result.content\n",
    "\n",
    "    # Show AI response\n",
    "    st.session_state.chat_ui.append((\"assistant\", ai_response))\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(ai_response)\n",
    "\n",
    "# ---------------------------\n",
    "# Sidebar Controls\n",
    "# ---------------------------\n",
    "with st.sidebar:\n",
    "    st.subheader(\"ðŸ§  Memory Controls\")\n",
    "\n",
    "    if st.button(\"Clear Chat (Short-Term)\"):\n",
    "        st.session_state.chat_ui = []\n",
    "        st.session_state.history_store = {}\n",
    "        st.experimental_rerun()\n",
    "\n",
    "    if st.button(\"Clear Long-Term Memory\"):\n",
    "        vectorstore.delete_collection()\n",
    "        st.success(\"Long-term memory cleared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d38a763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ddf2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed01982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5424150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('c5137e00-502a-4990-aeb8-a4c32a1fe189')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f36860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
