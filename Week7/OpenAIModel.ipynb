{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bf431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad657e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934f03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51858569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40638426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m sorry, but I donâ€™t have that information. My training only goes up until midâ€‘2024, and I canâ€™t provide details on events that happened after that date. If youâ€™d like to know about previous Indiaâ€“South Africa matches or general cricket stats, Iâ€™d be happy to help with that!"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Who won the match between India and South Africa on Dec 3rd 2025\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=8192,\n",
    "    top_p=1,\n",
    "    reasoning_effort=\"medium\",\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14092f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = OpenAI()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7688191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a quiet valley where the stars shone brighter than anywhere else, there lived a small unicorn named Liora. Her coat was soft and silver, and her horn glowed with the palest blue light, like moonlight on snow.\n",
      "\n",
      "Every unicorn in the valley had a special gift. Some could make flowers bloom with a stomp of their hooves, others could sing songs that made rainbows appear. Liora, however, did not yet know what her gift was.\n",
      "\n",
      "Each night, she watched the older unicorns practice their magic. She tried to help: she stomped her hooves over the grass, but no flowers came. She sang softly to the sky, but no rainbows formed. She dipped her horn into the river, hoping it would turn to sparkling sugar, but the water stayed water.\n",
      "\n",
      "One evening, feeling a little sad, Liora wandered away from the valley and climbed a small hill. Above her, the sky was dark and deep, sprinkled with thousands of tiny stars. The moon hung low and round, like a silver lantern.\n",
      "\n",
      "â€œI wish I knew what Iâ€™m meant to do,â€ she whispered.\n",
      "\n",
      "The wind rustled the grass in answer, gentle and cool. Liora lay down and gazed up, her horn glowing faintly. As she watched, she noticed something new: a star, dim and flickering at the edge of the sky, as if it were too tired to shine.\n",
      "\n",
      "â€œOh,â€ she breathed. â€œYou look lonely, too.â€\n",
      "\n",
      "She stood up and pointed her horn toward the little star. Her horn glowed brighter, then brighter still, sending a slender beam of soft blue light into the sky. The light touched the faint star, wrapping it in a gentle glow.\n",
      "\n",
      "The star quivered, then grew a little stronger. It twinkled back at her, as if saying thank you.\n",
      "\n",
      "Lioraâ€™s heart fluttered. â€œDid I do that?â€\n",
      "\n",
      "She tried again, focusing on another tiny, sleepy star. Her horn warmed and hummed, and once more, a ray of light reached up. The second star brightened, then the first one sparkled even more, as though they were waking each other up.\n",
      "\n",
      "All around her, the sky slowly changed. The dimmest stars began to glow, then to shine, until the whole night seemed to grow deeper and more beautiful. The valley behind her filled with a cool, gentle light, and the other unicorns looked up in wonder.\n",
      "\n",
      "â€œWho is brightening the stars?â€ they murmured.\n",
      "\n",
      "High on the little hill, Lioraâ€™s horn blazed softly like a lantern. She wasnâ€™t forcing the stars to glow; she was simply reminding them of their own light. One by one, they answered her, twinkling awake, until the sky was a blanket of sparkling silver.\n",
      "\n",
      "A soft voice drifted through the night, as if carried on the breeze. â€œLiora,â€ it said, â€œyour gift is to help the smallest lights shine.â€\n",
      "\n",
      "The voice felt like moonlight itself, and Liora understood. She didnâ€™t need to grow flowers or sing rainbows. Her magic was quieter: she made the night less lonely, the darkness less dark, by helping every hidden sparkle find its glow.\n",
      "\n",
      "When her horn finally dimmed, the stars stayed bright. The valley below shimmered with starlight, and the unicorns lay down to sleep, comforted by the soft, steady glow above them.\n",
      "\n",
      "Liora curled up on her hill, the moon smiling down. She no longer wondered what her gift was; she had found it among the stars.\n",
      "\n",
      "And as she closed her eyes, tiny new starsâ€”ones no one had ever noticed beforeâ€”winked into view, shining gently over the world, keeping watch through the quiet, peaceful night.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\"\n",
    ")\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266e6b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Responses.create() got an unexpected keyword argument 'frequency_penalty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-5.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a short bedtime story about a unicorn.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      5\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      6\u001b[0m     max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m      8\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Responses.create() got an unexpected keyword argument 'frequency_penalty'"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\",\n",
    "    temperature=0.7, # Creativity Control : 0.0 (more focused) to 1.0 (more creative)\n",
    "    top_p=1.0, # Nucleus Sampling: 0.0 to 1.0: 1.0 means consider all tokens : 0.5 means consider only top 50% probable tokens\n",
    "    max_output_tokens=200,\n",
    "    frequency_penalty=0.3, # Discourage Repetition: 0.0 to 2.0\n",
    "    presence_penalty=0.0 # Encourage New Topics: 0.0 to 2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bc7a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Chat Completion not Chat Response\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a bedtime story about a unicorn\"}],\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.3\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c80f8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Moonlit Journey of Luna the Unicorn**\n",
      "\n",
      "Once upon a time in a mystical land called Celestia, where the skies shimmered with rainbow colors and the trees whispered secrets to one another, there lived a gentle unicorn named Luna. She had a coat as white as freshly fallen snow and a mane that sparkled like stardust. But what made Luna truly special was her magnificent horn, which glowed softly in the moonlight, casting a silver light over everything around her.\n",
      "\n",
      "Luna loved to wander through the enchanted forest that surrounded her home. Each evening, as the sun dipped below the horizon and painted the sky with hues of orange and pink, she would set off on adventures, exploring hidden meadows filled with flowers that danced in the breeze.\n",
      "\n",
      "One evening, while wandering deeper into the forest than she had ever been before, Luna stumbled upon an ancient oak tree with twisting roots and shimmering leaves. As she approached, she heard a soft sobbing sound coming from beneath its branches. Curious and concerned, she stepped closer to investigate.\n",
      "\n",
      "Beneath the oak sat a small fairy named Tilly. Her wings were damp from tears, and her tiny face was streaked with sadness. \"Oh dear fairy,\" Luna asked gently, \"why do you weep under this beautiful tree?\"\n",
      "\n",
      "Tilly looked up at Luna with big teary eyes. \"I lost my way home during twilight,\" she sniffed, \"and now I can't find my way back to my village before nightfall! If I donâ€™t return soon, my friends will worry.\"\n",
      "\n",
      "Luna's heart swelled with compassion for Tilly. \"Do not worry! I will help you find your way home!\" With that promise made, Luna lowered herself so Tilly could climb onto her back.\n",
      "\n",
      "Together they set off on their adventure through the moonlit forest. The silver light from Lunaâ€™s horn illuminated their path as they galloped past sparkling streams and fields of glowing flowers that lit up like lanterns in the night.\n",
      "\n",
      "As they journeyed deeper into Celestia's enchanted woods, they encountered different magical creatures who offered their help along the wayâ€”wise old owls who shared stories of constellations guiding them northward and playful fireflies who danced around them like tiny stars.\n",
      "\n",
      "After what felt like hours of laughter and friendship under the night sky, they finally reached a clearing where Tilly recognized familiar flowers blooming brightlyâ€”a sign that they were close to her village!\n",
      "\n",
      "\"Thank you for helping me find my way!\" said Tilly joyfully as she fluttered off Lunaâ€™s back and began to twinkle like one of her beloved stars.\n",
      "\n",
      "Just then, Tilly turned back to face her new friend. â€œWait! Let me give you something special!â€ She waved her tiny hands in intricate patterns while whispering an ancient spell; suddenly glowing dust filled the air around them.\n",
      "\n",
      "â€œWhenever you need guidance or wish for adventure,â€ Tilly said with a smile, â€œjust look up at the stars! Theyâ€™ll always point you towards your dreams.â€\n",
      "\n",
      "With hearts full of joy from their newfound friendship and promises kept under starlit skies, they shared one last hug before parting waysâ€”Luna heading back through the enchanting woods while Tilly flitted toward her village where lights twinkled warmly against darkened hills.\n",
      "\n",
      "That night as Luna trotted home beneath countless stars shining brightly above her headâ€”the very same ones that now held secrets of new adventuresâ€”she felt grateful for both friendships made in unexpected places and magic found within simple journeys.\n",
      "\n",
      "And so every evening thereafter when Luna looked up at those twinkling stars glowing just for herâ€”she remembered sweet little Tilly and knew no matter how far apart they might beâ€”they would always share an unbreakable bond woven by kindness throughout forevermore.\n",
      "\n",
      "With dreams swirling like stardust in her heartâ€”and knowing adventure awaited each new dayâ€”Luna closed her eyes under that magnificent moonlightâ€¦ drifting off into peaceful slumber filled with dreams only unicorns can know.\n",
      "\n",
      "And so ends our taleâ€¦ Goodnight little dreamer; may your own adventures begin tonight among those twinkling stars too! âœ¨ðŸŒ™ðŸ¦„\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bacc63",
   "metadata": {},
   "source": [
    "## Test Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4585a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='Hi there, this is a regenerated audio sample for testing the OpenAI transcription API. This audio is short, clear, and suitable for your transcription experiments.', logprobs=None, usage=UsageTokens(input_tokens=88, output_tokens=33, total_tokens=121, type='tokens', input_token_details=UsageTokensInputTokenDetails(audio_tokens=88, text_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(\"speech_test_regenerated.mp3\", \"rb\")\n",
    "\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\",\n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6edfa",
   "metadata": {},
   "source": [
    "# GROQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04303a8",
   "metadata": {},
   "source": [
    "### Set the key in .env\n",
    "### load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bc382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b039b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd14fa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there something I can help you with?"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004f96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since my knowledge cutoff is December 2023, I'll provide information on AI research news from the period leading up to that date. However, please note that some of the information might have changed or been updated since then.\n",
      "\n",
      "Here are some of the latest developments in AI research from the past few months (up to December 2023):\n",
      "\n",
      "1. **Breakthroughs in Large Language Models:** Researchers have made significant progress in developing more efficient and accurate large language models (LLMs). For example, Meta AI's LLaMA model has shown excellent performance in various NLP tasks, and the researchers have also made improvements to the model architecture.\n",
      "\n",
      "2. **Advances in Explainable AI (XAI):** Researchers at Google have made strides in developing more interpretable and explainable AI models. They have created a new tool, Explainable Neural Networks (ENN), which can provide human-interpretable explanations for AI decisions.\n",
      "\n",
      "3. **AI for Cybersecurity:** Researchers at the University of California, Berkeley have developed a new AI-based system for detecting and preventing cyber attacks. The system uses machine learning algorithms to identify and block malicious traffic in real-time.\n",
      "\n",
      "4. **Advances in Reinforcement Learning:** Researchers at DeepMind have made significant breakthroughs in reinforcement learning (RL) techniques. They have developed new RL algorithms that can learn to solve complex tasks, such as robotic manipulation and game playing.\n",
      "\n",
      "5. **Quantum AI Research:** Researchers at the Massachusetts Institute of Technology (MIT) have started exploring the intersection of quantum computing and AI. They have developed new AI algorithms that can run on quantum hardware and potentially solve complex problems more efficiently than classical AI.\n",
      "\n",
      "6. **Ethics in AI Research:** The Association for the Advancement of Artificial Intelligence (AAAI) has released guidelines for addressing the ethics of AI research. The guidelines aim to promote transparency, accountability, and fairness in AI development.\n",
      "\n",
      "Please note that AI research is a rapidly evolving field, and there may be more recent developments that have not been included in this list.\n",
      "\n",
      "Please keep in mind, since my knowledge stopped in December, 2023. AI advancements could be much faster than what was reported."
     ]
    }
   ],
   "source": [
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Share the latest news about AI research from the past month.\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ba2d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from ollama) (2.12.4)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.27->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae013e7",
   "metadata": {},
   "source": [
    "# deepseek-r1:1.5b Using OLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d87d2ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky, known as coloration or chromacy, is primarily determined by the amount of sunlight reflected on the Earth's surface. Different parts of the sky have varying levels of this reflection because light reflecting off water particles in the atmosphere, such as clouds and mist, can pass through more air molecules than light from objects like buildings or cars that reflects off dust or other particles. This difference in reflection leads to slight variations in the hues we perceive when looking up at the sky. Additionally, atmospheric conditions, including temperature, humidity, and the presence of trace gases like carbon dioxide, influence how the sky appears.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='deepseek-r1:1.5b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "#print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370be03",
   "metadata": {},
   "source": [
    "# Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbdf6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc581ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Agentic AI refers to artificial intelligence systems that possess the ability to take autonomous actions, make decisions, and interact with the environment to achieve specific goals or tasks. Unlike traditional AI, which often operates under human direction and focuses on tasks like data analysis or pattern recognition, agentic AI can operate independently and adaptively.\\n\\nKey characteristics of agentic AI may include:\\n\\n1. **Autonomy**: The AI can perform tasks and make decisions without human intervention.\\n2. **Goal-oriented behavior**: It is designed to achieve specific objectives or goals, which could involve planning and decision-making.\\n3. **Adaptability**: Agentic AI can learn from its experiences and change its behavior based on new information or feedback from its environment.\\n4. **Interactivity**: These systems can often interact with complex environments or with humans and other agents to achieve their objectives.\\n\\nExamples of agentic AI can range from advanced robotics (such as autonomous drones or self-driving cars) to software agents in complex computational environments (like trading bots in financial markets).\\n\\nThe development and deployment of agentic AI raise various ethical and safety considerations, particularly regarding accountability, decision-making transparency, and the potential for unintended consequences. Organizations and researchers are actively exploring frameworks and guidelines to ensure that agentic AI systems are developed and used in responsible and beneficial ways.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 263, 'prompt_tokens': 23, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-CgusnSgmeatiONwJPioewSz9q07QI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--411c3209-dbcc-48c9-ac03-97491227e3e0-0' usage_metadata={'input_tokens': 23, 'output_tokens': 263, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "print(chain.invoke({\"question\": \"What is Agentic AI?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1781e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1daaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**What are Transformers?**\\n\\nTransformers are a type of neural network model used in machine learning and artificial intelligence. They\\'re called \"transformers\" because they transform the way we process and understand language (and other data).\\n\\n**How do Transformers Work?**\\n\\nImagine you\\'re having a conversation with a friend. You start with a sentence, and your friend responds with another sentence. But, how do they know what word to use next? They use context, right? They consider what you said before and try to make sense of it.\\n\\nTransformers work in a similar way. They look at a piece of text (like a sentence or a paragraph) and break it down into smaller chunks called \"tokens\" (like individual words). Then, they use these tokens to predict what comes next, just like your friend does.\\n\\nHere\\'s a simplified step-by-step explanation:\\n\\n1. **Tokenization**: Break down the text into individual words or tokens.\\n2. **Embedding**: Convert each token into a numerical vector (a list of numbers) that represents its meaning.\\n3. **Attention**: Look at all the tokens and decide which ones are most relevant to the current token (like your friend focusing on the most important parts of your sentence).\\n4. **Processing**: Use the relevant tokens to predict what comes next (like your friend suggesting a word).\\n5. **Output**: Generate a new token based on the predictions.\\n\\n**Benefits of Transformers**\\n\\nTransformers have several benefits:\\n\\n* **Self-Attention**: They can focus on specific parts of the text that are most relevant to the current token.\\n* **Parallel Processing**: They can process multiple tokens simultaneously, making them much faster than traditional neural networks.\\n* **Language Understanding**: They can learn to understand the nuances of language, allowing them to generate more accurate and coherent text.\\n\\n**Real-World Applications**\\n\\nTransformers have many real-world applications, including:\\n\\n* **Language Translation**: They can translate languages more accurately and efficiently than traditional methods.\\n* **Text Summarization**: They can summarize long pieces of text into concise, meaningful summaries.\\n* **Chatbots**: They can generate human-like responses to user queries.\\n\\nIn summary, transformers are powerful neural networks that can process and understand language in a more efficient and accurate way than traditional methods.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 460, 'prompt_tokens': 42, 'total_tokens': 502, 'completion_time': 0.725214473, 'completion_tokens_details': None, 'prompt_time': 0.001931846, 'prompt_tokens_details': None, 'queue_time': 0.052979864, 'total_time': 0.727146319}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--07d35f4b-dc5f-4866-96af-c7fc5975aa75-0' usage_metadata={'input_tokens': 42, 'output_tokens': 460, 'total_tokens': 502}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "response = llm.invoke(\"Explain transformers in simple words.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30faaa",
   "metadata": {},
   "source": [
    "## System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb5311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain embeddings in 3 bullet points.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in 3 bullet points.\"\n",
    ")\n",
    "\n",
    "print(template.format(topic=\"embeddings\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcbe49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'Apple', 'revenue': '$383B'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Extract company name and revenue from the text below.\n",
    "Return output ONLY in JSON format with keys company, revenue.\n",
    "\n",
    "Text:\n",
    "Apple generated $383B revenue in 2023.\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI()\n",
    "print(parser.parse(model.invoke(prompt).content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11425088",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e29a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "314370aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 embedding length: 1536\n",
      "[0.015356769785284996, 0.03452569618821144, 0.03314683213829994, 0.01639767736196518, -0.021115558221936226, -0.0155595438554883, 0.013437173329293728, 0.012734223157167435, -0.018749859184026718, 0.019087815657258034] ...\n",
      "Text 2 embedding length: 1536\n",
      "[-0.027849717065691948, 0.003486940171569586, 0.04356098920106888, 0.0014729317044839263, 0.014623391442000866, -0.01214989647269249, 0.015505146235227585, -0.00042477401439100504, 0.002828486729413271, 0.023143205791711807] ...\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Example text list\n",
    "texts = [\n",
    "    \"Retrieval-Augmented Generation (RAG) improves accuracy.\",\n",
    "    \"Embeddings convert text into high-dimensional vectors.\"\n",
    "]\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=texts\n",
    ")\n",
    "\n",
    "# Print embeddings\n",
    "for i, emb in enumerate(response.data):\n",
    "    print(f\"Text {i+1} embedding length:\", len(emb.embedding))\n",
    "    print(emb.embedding[:10], \"...\")  # show first 10 numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dc417df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 embedding length: 512\n",
      "[-0.006820265203714371, 0.01068376749753952, -0.022077158093452454, 0.030908022075891495, -0.06736687570810318, -0.03038763254880905, 0.06591609120368958, 0.033778052777051926, -0.00962721835821867, -0.008815093897283077] ...\n",
      "Text 2 embedding length: 512\n",
      "[-0.03966500610113144, -0.028670484200119972, 0.03462023660540581, -0.05522293224930763, 0.05333595722913742, -0.043862566351890564, -0.04640420898795128, -0.005848662927746773, -0.045826561748981476, 0.06434973329305649] ...\n",
      "Text 3 embedding length: 512\n",
      "[-0.005087872035801411, 0.039913903921842575, 0.016241736710071564, -0.00626326072961092, -0.004804299212992191, -0.030938206240534782, 0.03853302821516991, -0.001427111099474132, -0.020976169034838676, 0.027683284133672714] ...\n"
     ]
    }
   ],
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=texts,\n",
    "    dimensions=512\n",
    ")\n",
    "\n",
    "# Print embeddings\n",
    "for i, emb in enumerate(response.data):\n",
    "    print(f\"Text {i+1} embedding length:\", len(emb.embedding))\n",
    "    print(emb.embedding[:10], \"...\")  # show first 10 numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc608dc",
   "metadata": {},
   "source": [
    "#### Size\n",
    "    1. text-embedding-3-large : Default vector size: 3072 dimensions [Large]\n",
    "    2. text-embedding-3-small : 1536 dimensions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cd81210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "268a5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c468265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results:\n",
      "- Transfer learning speeds up deep learning training.\n",
      "- RAG improves retrieval accuracy for enterprise systems.\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Step 2. Sample documents\n",
    "docs = [\n",
    "    \"India won its Test match by 200 runs.\",\n",
    "    \"RAG improves retrieval accuracy for enterprise systems.\",\n",
    "    \"Transfer learning speeds up deep learning training.\"\n",
    "]\n",
    "\n",
    "# Step 3. Create vector store\n",
    "faiss_index = FAISS.from_texts(docs, embedding_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64c45063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results:\n",
      "- Transfer learning speeds up deep learning training.\n",
      "- RAG improves retrieval accuracy for enterprise systems.\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Search\n",
    "query = \"How do I improve AI accuracy?\"\n",
    "results = faiss_index.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Top results:\")\n",
    "for r in results:\n",
    "    print(\"-\", r.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2813f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_texts(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb7cd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12a452bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing FAISS index\n",
    "db = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35087d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = [\n",
    "    \"AI can automate repetitive tasks.\",\n",
    "    \"Machine learning models are improving healthcare outcomes.\",\n",
    "    \"The stock market crashed yesterday due to global tension.\",\n",
    "    \"Cats are very playful animals.\",\n",
    "    \"Python is widely used in data science.\",\n",
    "    \"Electric vehicles are becoming more popular.\",\n",
    "    \"The weather today is sunny with mild winds.\",\n",
    "    \"Football is the most popular sport in the world.\",\n",
    "    \"Quantum computing is the future of cryptography.\",\n",
    "    \"Deep learning helps in image recognition.\",\n",
    "    \"The restaurant serves Italian and Mexican food.\",\n",
    "    \"Traveling to Japan is on my wishlist.\",\n",
    "    \"Reinforcement learning trains agents via rewards.\",\n",
    "    \"Natural Language Processing enables chatbots.\",\n",
    "    \"The new iPhone was launched with major upgrades.\",\n",
    "    \"Meditation improves mental health.\",\n",
    "    \"Blockchain technology ensures secure transactions.\",\n",
    "    \"Yoga enhances flexibility and strength.\",\n",
    "    \"Cloud computing allows scalable applications.\",\n",
    "    \"Climate change impacts global ecosystems.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49e28f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fedbf86f-e0f3-4aa6-82a8-9438d174773f',\n",
       " '64fba312-22a9-440d-921e-1c029df9593d',\n",
       " '892017d6-430c-4215-abfc-e7dd386749f9',\n",
       " 'bbb04f95-0d53-4a0c-b4b0-dd6813cac7c9',\n",
       " 'dedf16ef-62e1-46af-b8b4-b0a663ca0d31',\n",
       " 'adc02ff3-8444-4583-9306-ab0a636b2f56',\n",
       " '55cfc178-a97c-41a2-9eff-d259ba1d4613',\n",
       " '5e6cb105-5166-4390-8617-86f0ffcfed28',\n",
       " '59cb40b5-4b3e-4d25-a79d-b95128d3afed',\n",
       " '5a585964-b038-4b3b-8a7d-69775f19282d',\n",
       " '511f5dd6-d287-42c1-a5ab-facff615d06f',\n",
       " '31b7c22b-d3ee-486f-aa7e-dc7f1710ef68',\n",
       " 'ecf6ba3d-a2e2-478f-a817-a4dc98ac4e27',\n",
       " '23b4fdaf-88b3-4977-bc0e-34d03675b16a',\n",
       " '2d26d37c-bcb1-40cc-9523-cd000ecea548',\n",
       " 'c3158f71-c5aa-4f3f-99e8-f4661c5e8e8d',\n",
       " '4c805f06-82ca-4078-ae92-e320e5edbaff',\n",
       " 'b0c43edd-4a34-4866-9bea-5e0594b92177',\n",
       " 'abe38cf7-043e-470a-84c2-ed29fa58ddf6',\n",
       " '0a0be554-5325-468e-a1c5-0f40917ec87e']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_texts(docs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26516d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated index\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb0e8c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top search results:\n",
      "- Machine learning models are improving healthcare outcomes.\n",
      "- AI can automate repetitive tasks.\n",
      "- Deep learning helps in image recognition.\n"
     ]
    }
   ],
   "source": [
    "query = \"How can AI help in healthcare?\"\n",
    "results = db.similarity_search(query, k=3)\n",
    "print(\"\\nTop search results:\")\n",
    "for r in results:\n",
    "    print(\"-\", r.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a62c4592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: RAG improves retrieval accuracy for enterprise systems.\n",
      "Score: 1.3513801\n",
      "---\n",
      "Text: Cloud computing allows scalable applications.\n",
      "Score: 1.5137949\n",
      "---\n",
      "Text: Transfer learning speeds up deep learning training.\n",
      "Score: 1.5689678\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "query = \"How do vector databases work?\"\n",
    "\n",
    "results = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(\"Text:\", doc.page_content)\n",
    "    print(\"Score:\", score)\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5de74c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index type: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"FAISS index type:\", db.index.metric_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335441d",
   "metadata": {},
   "source": [
    "#### distance\n",
    "1 -- Inner Product (higher is better)\n",
    "\n",
    "0 -- L2 Distance (Smaller is better)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028fab01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b35dfa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric type: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "texts = [\n",
    "    \"India won the cricket match.\",\n",
    "    \"FAISS is used for similarity search.\",\n",
    "    \"Embeddings turn text into vectors.\"\n",
    "]\n",
    "\n",
    "db = FAISS.from_texts(\n",
    "    texts,\n",
    "    emb,\n",
    "    distance_strategy=DistanceStrategy.COSINE\n",
    ")\n",
    "\n",
    "print(\"Metric type:\", db.index.metric_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef1968",
   "metadata": {},
   "source": [
    "#### Different Distance\n",
    "    1. DistanceStrategy.EUCLIDEAN (L2)\n",
    "        - L2\n",
    "        - Lower = closer\n",
    "        - Useful for numeric vectors, clustering\n",
    "    2. DistanceStrategy.COSINE\n",
    "        - Equivalent to cosine similarity\n",
    "        - Higher = closer\n",
    "        - Best for RAG, semantic search\n",
    "    3. DistanceStrategy.MAX_INNER_PRODUCT\n",
    "        - Higher = similar\n",
    "        - Good for ranking tasks\n",
    "        - Recommendation Systems (weighted embeddings), Product Ranking on E-commerce Platforms \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a20bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "# Cosine similarity\n",
    "db_cos = FAISS.from_texts(texts, emb, distance_strategy=DistanceStrategy.COSINE)\n",
    "\n",
    "# Euclidean distance\n",
    "db_l2 = FAISS.from_texts(texts, emb, distance_strategy=DistanceStrategy.EUCLIDEAN)\n",
    "\n",
    "# Max inner-product\n",
    "db_ip = FAISS.from_texts(texts, emb, distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e542d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d60a7ac8",
   "metadata": {},
   "source": [
    "## Effective Prompt\n",
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42593ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regulation does not explicitly cover this point. Section 4.1 specifies reporting requirements for transactions above $10,000 but does not differentiate between domestic and foreign transactions.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI()\n",
    "\n",
    "# Mock RAG retrieved content\n",
    "retrieved_regulation_chunks = \"\"\"\n",
    "Section 4.1: Transactions above $10,000 must be reported within 24 hours.\n",
    "Section 5.3: All foreign transactions require dual authorization.\n",
    "\"\"\"\n",
    "\n",
    "# User question\n",
    "audit_team_question = \"Do we need to report domestic transactions above $15,000?\"\n",
    "\n",
    "# Construct Better Prompt\n",
    "prompt = f\"\"\"\n",
    "You are a Financial Compliance Assistant for internal audit teams.\n",
    "Use ONLY the regulatory text provided in the CONTEXT section.\n",
    "For the given QUESTION, follow these rules:\n",
    "\n",
    "1. Provide a concise answer in 2â€“3 sentences.\n",
    "2. Cite the specific regulation clause numbers or section titles you used.\n",
    "3. If the regulation does not explicitly mention the requested information, state:\n",
    "   \"The regulation does not explicitly cover this point.\"\n",
    "4. Do NOT guess or infer new rules. Do NOT provide advice beyond the context.\n",
    "\n",
    "CONTEXT:\n",
    "{retrieved_regulation_chunks}\n",
    "\n",
    "QUESTION:\n",
    "{audit_team_question}\n",
    "\"\"\"\n",
    "\n",
    "# Invoke LLM\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt,\n",
    "    max_output_tokens=250\n",
    ")\n",
    "\n",
    "# Output\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7637bb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, you are not allowed to work from home for 10 days in a month, as the policy permits work-from-home for up to 8 days per month with manager approval (Section 4.1).\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Mock HR policy chunk (normally retrieved via RAG)\n",
    "retrieved_hr_policy_chunks = \"\"\"\n",
    "Section 2.3: Employees can take up to 12 paid sick leaves per calendar year.\n",
    "Section 4.1: Work-from-home is allowed for up to 8 days per month with manager approval.\n",
    "Section 5.4: Overtime pay applies only when weekly work exceeds 40 hours.\n",
    "\"\"\"\n",
    "\n",
    "employee_question = \"Am I allowed to work from home for 10 days in a month?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an Internal HR Policy Assistant.\n",
    "Use ONLY the HR policy text provided in the CONTEXT section.\n",
    "For the given QUESTION, follow these rules:\n",
    "\n",
    "1. Provide a clear answer in 2â€“4 sentences.\n",
    "2. Cite the exact HR policy section numbers used.\n",
    "3. If the policy does not explicitly cover the question, say:\n",
    "   \"The policy does not explicitly cover this issue.\"\n",
    "4. Do NOT invent new HR rules or benefits.\n",
    "\n",
    "CONTEXT:\n",
    "{retrieved_hr_policy_chunks}\n",
    "\n",
    "QUESTION:\n",
    "{employee_question}\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt,\n",
    "    max_output_tokens=200\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "824c30e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The policy does not explicitly address this issue.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Mock Security policy chunk (normally from vector DB)\n",
    "retrieved_security_policy_chunks = \"\"\"\n",
    "Control ID SEC-12: All company laptops must use full-disk encryption.\n",
    "Control ID SEC-18: Passwords must be changed every 90 days.\n",
    "Control ID SEC-27: Multi-factor authentication (MFA) is mandatory for VPN access.\n",
    "\"\"\"\n",
    "\n",
    "it_security_question = \"Is multi-factor authentication required for accessing company email?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an Internal Information Security Policy Assistant.\n",
    "Use ONLY the security policy text provided in the CONTEXT section.\n",
    "For the given QUESTION, follow these rules:\n",
    "\n",
    "1. Provide a precise answer in 2â€“4 sentences.\n",
    "2. Cite the exact control IDs you used.\n",
    "3. If the policy does not directly address the question, state:\n",
    "   \"The policy does not explicitly address this issue.\"\n",
    "4. Do NOT invent new security requirements or controls.\n",
    "5. Maintain compliance-ready, factual language.\n",
    "\n",
    "CONTEXT:\n",
    "{retrieved_security_policy_chunks}\n",
    "\n",
    "QUESTION:\n",
    "{it_security_question}\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt,\n",
    "    max_output_tokens=200\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a15126",
   "metadata": {},
   "source": [
    "## Types\n",
    "    1. Zero Shot\n",
    "    2. Few Shot\n",
    "    3. Chain of Thoughts\n",
    "    4. Schema guided prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57e0980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the message is negative.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"Classify the sentiment of the message: 'The delivery was late and the product was damaged.'\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471119f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Classify the IT support issue into one of: [Network, Hardware, Software]\n",
    "\n",
    "Example:\n",
    "Input: \"WiFi keeps dropping.\"\n",
    "Output: Network\n",
    "\n",
    "Example:\n",
    "Input: \"My laptop screen is cracked.\"\n",
    "Output: Hardware\n",
    "\n",
    "Now classify:\n",
    "Input: \"Outlook is not syncing emails.\"\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd34e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the percentage growth in revenue, you can use the following formula:\n",
      "\n",
      "\\[\n",
      "\\text{Percentage Growth} = \\left( \\frac{\\text{New Revenue} - \\text{Old Revenue}}{\\text{Old Revenue}} \\right) \\times 100\n",
      "\\]\n",
      "\n",
      "1. **Identify the old and new revenue:**\n",
      "   - Old Revenue = â‚¹80 lakh\n",
      "   - New Revenue = â‚¹120 lakh\n",
      "\n",
      "2. **Calculate the difference:**\n",
      "   - Difference = New Revenue - Old Revenue\n",
      "   - Difference = â‚¹120 lakh - â‚¹80 lakh = â‚¹40 lakh\n",
      "\n",
      "3. **Plug the values into the percentage growth formula:**\n",
      "   \\[\n",
      "   \\text{Percentage Growth} = \\left( \\frac{â‚¹40 \\text{ lakh}}{â‚¹80 \\text{ lakh}} \\right) \\times 100\n",
      "   \\]\n",
      "\n",
      "4. **Calculate:**\n",
      "   \\[\n",
      "   \\text{Percentage Growth} = 0.5 \\times 100 = 50\\%\n",
      "   \\]\n",
      "\n",
      "Therefore, the percentage growth in revenue is **50%**.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "COTprompt = \"\"\"\n",
    "Think step-by-step and solve this:\n",
    "\n",
    "A company made â‚¹80 lakh revenue last year.\n",
    "This year revenue increased to â‚¹120 lakh.\n",
    "What is the percentage growth?\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=COTprompt\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e049b33",
   "metadata": {},
   "source": [
    "#### How to fix the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5302651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "parser = JsonOutputParser()\n",
    "JSonprompt = \"\"\"\n",
    "Compute revenue growth and return ONLY JSON:\n",
    "{\n",
    "  \"old\": 0,\n",
    "  \"new\": 0,\n",
    "  \"growth_pct\": 0\n",
    "}\n",
    "\n",
    "Old revenue: 80\n",
    "New revenue: 120\n",
    "\n",
    "Do not include text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=JSonprompt\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c644e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'old': 80, 'new': 120, 'growth_pct': 50}\n"
     ]
    }
   ],
   "source": [
    "result = parser.parse(response.output_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbaf42",
   "metadata": {},
   "source": [
    "## TOOLS and AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f125c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-community\n",
      "Version: 0.0.20\n",
      "Summary: Community contributed LangChain integrations.\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/anaconda3/envs/AAI/lib/python3.12/site-packages\n",
      "Requires: aiohttp, dataclasses-json, langchain-core, langsmith, numpy, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffc6615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (0.0.350)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (0.1.23)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (0.0.20)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (1.1.0)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
      "  Using cached langsmith-0.4.49-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.12.0-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Downloading langchain-1.1.0-py3-none-any.whl (101 kB)\n",
      "Using cached langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
      "Downloading langgraph-1.0.4-py3-none-any.whl (157 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.2.10-py3-none-any.whl (58 kB)\n",
      "Using cached langsmith-0.4.49-py3-none-any.whl (410 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Downloading ormsgpack-1.12.0-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (369 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-macosx_10_13_x86_64.whl (32 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain-community, langchain\n",
      "\u001b[2K  Attempting uninstall: langsmith\n",
      "\u001b[2K    Found existing installation: langsmith 0.0.87\n",
      "\u001b[2K    Uninstalling langsmith-0.0.87:\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.0.87\n",
      "\u001b[2K  Attempting uninstall: langchain-coreâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/10\u001b[0m [langsmith]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.1.23â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/10\u001b[0m [langsmith]\n",
      "\u001b[2K    Uninstalling langchain-core-0.1.23:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/10\u001b[0m [langsmith]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.1.23â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/10\u001b[0m [langsmith]\n",
      "\u001b[2K  Attempting uninstall: langchain-community[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/10\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.0.20â”â”â”\u001b[0m \u001b[32m 6/10\u001b[0m [langgraph-prebuilt]\n",
      "\u001b[2K    Uninstalling langchain-community-0.0.20:\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/10\u001b[0m [langchain-community]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.0.20â”â”â”â”â”\u001b[0m \u001b[32m 8/10\u001b[0m [langchain-community]\n",
      "\u001b[2K  Attempting uninstall: langchainâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/10\u001b[0m [langchain-community]\n",
      "\u001b[2K    Found existing installation: langchain 0.0.350\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/10\u001b[0m [langchain-community]\n",
      "\u001b[2K    Uninstalling langchain-0.0.350:â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/10\u001b[0m [langchain-community]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.0.3500m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/10\u001b[0m [langchain-community]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/10\u001b[0m [langchain]10\u001b[0m [langchain]unity]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-1.1.0 langchain-community-0.4.1 langchain-core-1.1.0 langgraph-1.0.4 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.10 langsmith-0.4.49 ormsgpack-1.12.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n",
    "!pip install -U langchain langchain-core langchain-community langchain-openai langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4b5776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ddgs\n",
      "  Downloading ddgs-9.9.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from ddgs) (8.1.8)\n",
      "Collecting primp>=0.15.0 (from ddgs)\n",
      "  Downloading primp-0.15.0-cp38-abi3-macosx_10_12_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=4.9.4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from ddgs) (5.3.0)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Requirement already satisfied: brotli in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Using cached socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
      "Downloading ddgs-9.9.2-py3-none-any.whl (41 kB)\n",
      "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
      "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Using cached socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading primp-0.15.0-cp38-abi3-macosx_10_12_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: socksio, primp, hyperframe, hpack, fake-useragent, h2, ddgs\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7/7\u001b[0m [ddgs][32m6/7\u001b[0m [ddgs]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ddgs-9.9.2 fake-useragent-2.2.0 h2-4.3.0 hpack-4.1.0 hyperframe-6.1.0 primp-0.15.0 socksio-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e172229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-search\n",
      "  Downloading youtube_search-2.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from youtube-search) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->youtube-search) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->youtube-search) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->youtube-search) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->youtube-search) (2025.10.5)\n",
      "Downloading youtube_search-2.1.2-py3-none-any.whl (3.4 kB)\n",
      "Installing collected packages: youtube-search\n",
      "Successfully installed youtube-search-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd536f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages:\n",
    "# pip install langchain langchain-community langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Predefined community tools\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "#from langchain_community.tools import WikipediaQueryRun\n",
    "#from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "\n",
    "\n",
    "# Intitialize Tools\n",
    "duckduckgo = DuckDuckGoSearchRun()\n",
    "tavily = TavilySearchResults(max_results=3,)\n",
    "youtube = YouTubeSearchTool()\n",
    "tools = [duckduckgo, tavily, youtube]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "280463aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind Tools to LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",  temperature=0).bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa00972d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x17be4f980>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x17c3d8260>, root_client=<openai.OpenAI object at 0x17bfde1b0>, root_async_client=<openai.AsyncOpenAI object at 0x17c3d85c0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), kwargs={'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'youtube_search', 'description': 'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63168c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1. DuckDuckGo Search ===\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 205, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-ChVxOKWcMUZPBMqXsmAraCIW6oqXh', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--d9a9fe28-134e-4a6d-872b-db02a5676904-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'latest AI news in India'}, 'id': 'call_smPJd23vWwwOrVixinVSReDF', 'type': 'tool_call'}] usage_metadata={'input_tokens': 205, 'output_tokens': 22, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 1. DuckDuckGo Search ===\")\n",
    "print(llm.invoke(\"Search for the latest AI news in India.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a67efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2. Tavily Web Search (factual search) ===\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 210, 'total_tokens': 235, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-ChT3Na8XawnSabmIC0CzK7WrC8iU5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--01fe5bdc-9f18-41a3-a719-cf3bc186bb44-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'renewable energy market 2025 facts'}, 'id': 'call_ncIFwBR09VdhiVbyQHb4c4jp', 'type': 'tool_call'}] usage_metadata={'input_tokens': 210, 'output_tokens': 25, 'total_tokens': 235, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 2. Tavily Web Search (factual search) ===\")\n",
    "print(llm.invoke(\"Find the top 3 facts about renewable energy market 2025.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ac78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 3. YouTube Search ===\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 207, 'total_tokens': 224, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-ChT3QgOhkLw4EsuyUbyluzQGmr6mt', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--4d63f2db-2db5-446c-8eb0-d6e37a584ce4-0' tool_calls=[{'name': 'youtube_search', 'args': {'query': 'Python programming for beginners'}, 'id': 'call_C04Qg3uCDGeAsqE6EcUyCrPK', 'type': 'tool_call'}] usage_metadata={'input_tokens': 207, 'output_tokens': 17, 'total_tokens': 224, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 3. YouTube Search ===\")\n",
    "print(llm.invoke(\"Find useful YouTube videos for beginners in Python programming.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff5994",
   "metadata": {},
   "source": [
    "## For Every human Message LLM will identify which tool to be used and then invoke the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1afafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "tools = [duckduckgo, tavily, youtube]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db706139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai(query):\n",
    "    print(f\"\\n=== USER QUERY: {query} ===\")\n",
    "\n",
    "    result = llm.invoke([HumanMessage(content=query)])\n",
    "\n",
    "    # FIX: Read tool calls from result.tool_calls\n",
    "    tool_calls = result.tool_calls or []\n",
    "    print(tool_calls)\n",
    "\n",
    "    if tool_calls:\n",
    "        call = tool_calls[0]\n",
    "        tool_name = call[\"name\"]\n",
    "        tool_args = call[\"args\"]\n",
    "\n",
    "        print(f\"\\nðŸ”§ LLM SELECTED TOOL â†’ {tool_name}\")\n",
    "        print(f\"ðŸ”¢ Tool Arguments â†’ {tool_args}\")\n",
    "\n",
    "        # ---- Run the actual tool ----\n",
    "        if \"duck\" in tool_name.lower():\n",
    "            tool_output = duckduckgo.run(tool_args[\"query\"])\n",
    "\n",
    "        elif \"tavily\" in tool_name.lower():\n",
    "            tool_output = tavily.run(tool_args)\n",
    "\n",
    "        elif \"youtube\" in tool_name.lower():\n",
    "            tool_output = youtube.run(tool_args[\"query\"])\n",
    "\n",
    "        else:\n",
    "            tool_output = f\"â“ Unknown tool selected â†’ {tool_name}\"\n",
    "\n",
    "        print(\"\\nðŸ›  TOOL OUTPUT:\")\n",
    "        print(tool_output)\n",
    "\n",
    "        # Final LLM polishing\n",
    "        final_answer = llm.invoke(\n",
    "            f\"User query: {query}\\nTool output: {tool_output}\\nGive a clean final answer.\"\n",
    "        )\n",
    "        print(\"\\nðŸ§  FINAL ANSWER:\")\n",
    "        print(final_answer.content)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nðŸ¤– LLM responded WITHOUT a tool:\")\n",
    "        print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee99d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== USER QUERY: Give me recent research about quantum computing. ===\n",
      "[{'name': 'tavily_search_results_json', 'args': {'query': 'recent research in quantum computing 2023'}, 'id': 'call_76Lyfz5PyMZYlsqQ9lKJRQTJ', 'type': 'tool_call'}]\n",
      "\n",
      "ðŸ”§ LLM SELECTED TOOL â†’ tavily_search_results_json\n",
      "ðŸ”¢ Tool Arguments â†’ {'query': 'recent research in quantum computing 2023'}\n",
      "\n",
      "ðŸ›  TOOL OUTPUT:\n",
      "[{'title': 'Breakthroughs in Quantum Computing - Wevolver', 'url': 'https://www.wevolver.com/article/breakthroughs-in-quantum-computing', 'content': 'Another recent pivotal development in the quantum computing field was the shift from emphasizing processor benchmarks to focusing on practical implementations. This transition is vital for transforming quantum computing from a theoretical concept into an applied technology with real-world applications. An updated analysis for 2023 projects indicates that industries like automotive, chemicals, financial services, and life sciences could see an economic impact of up to $1.3 trillion by 2035, [...] ## Conclusion\\n\\n2023 was a transformative year for quantum computing, marked by remarkable achievements and promising trends that extended beyond academia to practical, real-world applications. These developments, led by collaborations between industry giants and leading universities, pave the way for quantum technologies that promise to revolutionize fields like cryptography, medicine, and energy. [...] Good communication is paramount, quantum or otherwise, and 2023 also saw some excellent academic and corporate networking pushing quantum technology forward. Amazon Web Services (AWS), in collaboration with Harvard University, achieved a breakthrough in quantum networking that could enhance the speed and efficiency of classical telecom networks. Researchers developed a new method for packaging optical fibers that addresses the long-standing issue of data degradation over distances. The method', 'score': 0.9075175}, {'title': 'Year in Review: The Big Stories That Rocked Quantum Research ...', 'url': 'https://thequantuminsider.com/2023/12/29/year-in-review-the-big-stories-that-rocked-quantum-research-and-quantum-business-in-2023/', 'content': 'On the research and development end of the quantum industry, it was anything but quiet. Quantum scientists from both companies and research institutions â€” as well as many industry-academic collaborations â€” made unprecedented progress during the year.\\n\\nResponsive Image\\n\\nHere are just a few of the stories that rocked quantum in 2023.\\n\\n### Research\\n\\n### Harvard Announces Major Advance in Error Correction Perform Complex Algorithms on 48 Logical Qubits\\n\\nQuEra Nature\\n\\nQuEra Nature [...] From all indications, investment in the quantum industry quieted in 2023, compared to the explosion of funding rounds in 2021/22. Most industries, besides artificial intelligence, experienced this trend during the year.\\n\\nHowever, this relative quiet was interrupted with some major funding news, which weâ€™ll touch on below. [...] # Year in Review: The Big Stories That Rocked Quantum Research And Quantum Business in 2023\\n\\nnews that rocked quantum\\nnews that rocked quantum\\nHub\\nHub\\n\\nIn this list weâ€™ll take a look at some of the major news developments in the quantum industry by category â€” research, business, and national.', 'score': 0.8622012}, {'title': 'Publications on Quantum Computing', 'url': 'https://www.quera.com/publications', 'content': '[Japanese language] 2-page introduction to QuEra\\n\\n2-page introduction, Japanese language\\n\\nJune 23, 2023\\n\\nQuantum and the HPC Center\\n\\nAccelerating Research and Innovation with Quantum Computing in Your HPC Center\\n\\nJune 18, 2023\\n\\nA detailed introduction to QuEraâ€™s 256-qubit neutral-atom quantum computer [...] A vendor-neutral, modality-agnostic checklist of achievements toward large-scale, fault-tolerant quantum computing\\n\\nJanuary 21, 2025\\n\\nThe January 2025 Quantum Readiness Report\\n\\nGlobal quantum budgets set to surge by nearly 20% as confidence grows globally\\n\\nAugust 6, 2024\\n\\n2024 Survey Report: The Current and Future State of Quantum Computing\\n\\nA comprehensive analysis based on the recent survey conducted by QuEra Computing in June 2024\\n\\nJune 10, 2024 [...] Quantum Reservoir Computing for Credit Card Default Prediction on a Neutral Atom Platform\\n\\nJune 26, 2025\\n\\nResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers\\n\\nJune 10, 2025\\n\\nQuantum Adiabatic Generation of Human-Like Passwords\\n\\n.png)\\n\\nApril 8, 2025\\n\\nQuantum Adiabatic Optimization with Rydberg Arrays: Localization Phenomena and Encoding Strategies\\n\\nMarch 16, 2025', 'score': 0.7732339}]\n",
      "\n",
      "ðŸ§  FINAL ANSWER:\n",
      "Here are some recent research highlights in the field of quantum computing:\n",
      "\n",
      "1. **Breakthroughs in Quantum Computing**  \n",
      "   - **Source**: [Wevolver](https://www.wevolver.com/article/breakthroughs-in-quantum-computing)  \n",
      "   - **Summary**: 2023 marked a significant shift in quantum computing, focusing on practical implementations rather than just processor benchmarks. This transition is expected to impact industries such as automotive, chemicals, financial services, and life sciences, potentially generating an economic impact of up to $1.3 trillion by 2035. Notable advancements include a collaboration between Amazon Web Services and Harvard University, which achieved a breakthrough in quantum networking to enhance classical telecom networks.\n",
      "\n",
      "2. **Year in Review: Major Advances in Quantum Research**  \n",
      "   - **Source**: [The Quantum Insider](https://thequantuminsider.com/2023/12/29/year-in-review-the-big-stories-that-rocked-quantum-research-and-quantum-business-in-2023/)  \n",
      "   - **Summary**: The year 2023 saw unprecedented progress in quantum research, with significant developments in error correction and complex algorithms on logical qubits. Despite a slowdown in investment compared to previous years, major funding news emerged, highlighting the ongoing evolution of the quantum industry.\n",
      "\n",
      "3. **Publications on Quantum Computing**  \n",
      "   - **Source**: [QuEra](https://www.quera.com/publications)  \n",
      "   - **Summary**: QuEra has published various documents detailing advancements in quantum computing, including a comprehensive analysis of the current and future state of quantum technologies. Their research includes topics like quantum reservoir computing and frameworks for implementing neural networks on quantum computers.\n",
      "\n",
      "These articles reflect the dynamic and rapidly evolving landscape of quantum computing research and its potential applications.\n"
     ]
    }
   ],
   "source": [
    "ask_ai(\"Give me recent research about quantum computing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b14266cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== USER QUERY: Suggest YouTube videos to learn Python. ===\n",
      "[]\n",
      "\n",
      "ðŸ¤– LLM responded WITHOUT a tool:\n",
      "Here are some popular YouTube channels and specific video recommendations to help you learn Python:\n",
      "\n",
      "### YouTube Channels\n",
      "\n",
      "1. **Corey Schafer**\n",
      "   - Known for clear explanations and practical examples.\n",
      "   - **Recommended Video**: \"Python Tutorial for Beginners - Full Course in 11 Hours [2020]\"\n",
      "\n",
      "2. **freeCodeCamp.org**\n",
      "   - Offers comprehensive tutorials and full courses.\n",
      "   - **Recommended Video**: \"Python for Everybody - Full Course with Dr. Charles Severance\"\n",
      "\n",
      "3. **Programming with Mosh**\n",
      "   - Focuses on practical programming skills.\n",
      "   - **Recommended Video**: \"Python Tutorial for Beginners - Learn Python in 1 Hour\"\n",
      "\n",
      "4. **Traversy Media**\n",
      "   - Covers a wide range of programming topics, including Python.\n",
      "   - **Recommended Video**: \"Python Crash Course - Learn Python in 1 Hour\"\n",
      "\n",
      "5. **Sentdex**\n",
      "   - Focuses on Python for data analysis, machine learning, and more.\n",
      "   - **Recommended Video**: \"Python Programming for Beginners - Full Course\"\n",
      "\n",
      "6. **The Net Ninja**\n",
      "   - Offers a series of tutorials on various programming languages, including Python.\n",
      "   - **Recommended Video**: \"Python for Beginners - Full Course\"\n",
      "\n",
      "### Specific Video Recommendations\n",
      "\n",
      "1. **\"Learn Python - Full Course for Beginners [Tutorial]\" by freeCodeCamp.org**\n",
      "   - A comprehensive 4-hour course that covers the basics of Python.\n",
      "\n",
      "2. **\"Python Tutorial for Beginners - Learn Python in 10 Minutes\" by Corey Schafer**\n",
      "   - A quick introduction to Python for absolute beginners.\n",
      "\n",
      "3. **\"Python Crash Course\" by Traversy Media**\n",
      "   - A fast-paced introduction to Python, covering the essentials.\n",
      "\n",
      "4. **\"Python for Data Science - Full Course\" by freeCodeCamp.org**\n",
      "   - If you're interested in data science, this course covers Python in that context.\n",
      "\n",
      "5. **\"Automate the Boring Stuff with Python\" by Al Sweigart**\n",
      "   - A practical approach to learning Python by automating everyday tasks.\n",
      "\n",
      "### Additional Resources\n",
      "\n",
      "- **Kaggle**: Look for Python tutorials related to data science and machine learning.\n",
      "- **Codecademy**: While not a YouTube channel, they offer interactive Python courses that complement video learning.\n",
      "\n",
      "These resources should provide a solid foundation in Python, whether you're a complete beginner or looking to enhance your skills. Happy coding!\n"
     ]
    }
   ],
   "source": [
    "ask_ai(\"Suggest YouTube videos to learn Python.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f69adc",
   "metadata": {},
   "source": [
    "### Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "848f09ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/lr5c6v793qbcszm54dsf6y440000gn/T/ipykernel_43602/341687680.py:28: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(llm, tools)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of multiplying 9 and 7 is 63. \n",
      "\n",
      "Also, hello Sahil! Welcome.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# -------------------------\n",
    "# 1. Define tools\n",
    "# -------------------------\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def greet(name: str) -> str:\n",
    "    \"\"\"Return greeting.\"\"\"\n",
    "    return f\"Hello {name}! Welcome.\"\n",
    "\n",
    "tools = [multiply, greet]\n",
    "\n",
    "# -------------------------\n",
    "# 2. LLM\n",
    "# -------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Build Agent (LangGraph ReAct Agent)\n",
    "# -------------------------\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Run agent\n",
    "# -------------------------\n",
    "result = agent.invoke({\"messages\": \"Multiply 9 and 7, then greet Sahil.\"})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21cea2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of multiplying 10 and 7 is 70. \n",
      "\n",
      "If you meant to add 10 and 7, the sum is 17.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Add 10 and 7\"})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a3ddc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.7.13-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from tavily-python) (2.32.5)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from tavily-python) (0.12.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->tavily-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->tavily-python) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->tavily-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests->tavily-python) (2025.10.5)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx->tavily-python) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from anyio->httpx->tavily-python) (1.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from anyio->httpx->tavily-python) (4.15.0)\n",
      "Downloading tavily_python-0.7.13-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: tavily-python\n",
      "Successfully installed tavily-python-0.7.13\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.1.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.4.49)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tavily-python\n",
    "!pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c9a9faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: langgraph in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (1.0.4)\n",
      "Requirement already satisfied: tavily-python in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (0.7.13)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/AAI/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community langchain-openai langgraph tavily-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
