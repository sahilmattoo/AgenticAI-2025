{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488d7397",
   "metadata": {},
   "source": [
    "This is optional in case needs to connect to previous module can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e237a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n",
      "0.3.24\n"
     ]
    }
   ],
   "source": [
    "# check langchain version it should be 0.3 if not uncomment below pip command to install the correct version\n",
    "import langchain, langchain_community\n",
    "print(langchain.__version__)\n",
    "print(langchain_community.__version__)\n",
    "# !pip install langchain==0.3.27 langchain-openai==0.3.33 langchain-community==0.3.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea112fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# The LLM \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa943a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENHANCED TOOL SELECTION SYSTEM\n",
      "Testing 3 different requests...\n",
      "\n",
      "#1: What's 15 * 24 + 8?\n",
      "──────────────────────────────────────────────────\n",
      "Selected tool: math\n",
      "Let me calculate that for you: 15 * 24 + 8 = 368\n",
      "\n",
      "#2: What's the weather in New York?\n",
      "──────────────────────────────────────────────────\n",
      "Selected tool: weather\n",
      "Weather update for What'S The   New York?: Partly Cloudy with temperatures around 85°F. Humidity is 65%. Dress accordingly!\n",
      "\n",
      "#3: Tell me about quantum computing\n",
      "──────────────────────────────────────────────────\n",
      "Selected tool: knowledge\n",
      "Information about quantum computing: Quantum computing uses quantum bits (qubits) that can exist in multiple states simultaneously, enabling them to solve certain problems much faster than classical computers. Key players include IBM, Google, and Microsoft in developing practical quantum systems.\n",
      "\n",
      "Tool selection testing completed!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableBranch, RunnableLambda\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Enhanced tool functionalities with more realistic responses\n",
    "def calculate_math(expression):\n",
    "    \"\"\"Enhanced math calculation with actual computation\"\"\"\n",
    "    try:\n",
    "        # Safe evaluation of common math expressions\n",
    "        expression_clean = expression.lower().replace('what\\'s', '').replace('what is', '').strip('? ')\n",
    "        \n",
    "        # Map words to operators\n",
    "        word_to_operator = {\n",
    "            'plus': '+', 'add': '+', 'sum': '+',\n",
    "            'minus': '-', 'subtract': '-', 'difference': '-',\n",
    "            'times': '*', 'multiply': '*', 'product': '*', 'x': '*',\n",
    "            'divided by': '/', 'divide': '/', 'over': '/',\n",
    "            'modulo': '%', 'mod': '%',\n",
    "            'power': '**', 'to the power of': '**'\n",
    "        }\n",
    "        \n",
    "        # Replace words with operators\n",
    "        for word, operator in word_to_operator.items():\n",
    "            expression_clean = expression_clean.replace(word, operator)\n",
    "        \n",
    "        # Safe evaluation\n",
    "        result = eval(expression_clean, {\"__builtins__\": {}}, {})\n",
    "        \n",
    "        explanations = [\n",
    "            f\"Let me calculate that for you: {expression_clean} = {result}\",\n",
    "            f\"The answer to {expression_clean} is {result}\",\n",
    "            f\"After calculating: {expression_clean} = {result}\"\n",
    "        ]\n",
    "        return random.choice(explanations)\n",
    "        \n",
    "    except:\n",
    "        explanations = [\n",
    "            f\"I understand you want to calculate: '{expression}'. While I can't evaluate complex expressions safely, here's what I suggest: break it down into smaller steps or use a calculator for precise results.\",\n",
    "            f\"For the calculation '{expression}', I recommend using a dedicated math tool or calculator for accurate results.\"\n",
    "        ]\n",
    "        return random.choice(explanations)\n",
    "\n",
    "def get_weather(location):\n",
    "    \"\"\"Enhanced weather simulation with realistic data\"\"\"\n",
    "    locations_weather = {\n",
    "        \"new york\": {\"temp\": random.randint(65, 85), \"condition\": \"Partly Cloudy\", \"humidity\": \"65%\"},\n",
    "        \"london\": {\"temp\": random.randint(50, 65), \"condition\": \"Rainy\", \"humidity\": \"85%\"},\n",
    "        \"tokyo\": {\"temp\": random.randint(70, 90), \"condition\": \"Sunny\", \"humidity\": \"70%\"},\n",
    "        \"paris\": {\"temp\": random.randint(60, 75), \"condition\": \"Cloudy\", \"humidity\": \"75%\"},\n",
    "        \"sydney\": {\"temp\": random.randint(75, 95), \"condition\": \"Sunny\", \"humidity\": \"60%\"},\n",
    "        \"dubai\": {\"temp\": random.randint(85, 105), \"condition\": \"Clear\", \"humidity\": \"45%\"}\n",
    "    }\n",
    "    \n",
    "    location_lower = location.lower()\n",
    "    for loc, data in locations_weather.items():\n",
    "        if loc in location_lower:\n",
    "            weather_info = data\n",
    "            break\n",
    "    else:\n",
    "        # Default weather for unknown locations\n",
    "        weather_info = {\n",
    "            \"temp\": random.randint(60, 80), \n",
    "            \"condition\": random.choice([\"Sunny\", \"Cloudy\", \"Partly Cloudy\"]),\n",
    "            \"humidity\": f\"{random.randint(50, 80)}%\"\n",
    "        }\n",
    "    \n",
    "    responses = [\n",
    "        f\"Current weather in {location.title()}: {weather_info['temp']}°F, {weather_info['condition']}, Humidity: {weather_info['humidity']}. Perfect time to enjoy the outdoors!\",\n",
    "        f\"Weather update for {location.title()}: {weather_info['condition']} with temperatures around {weather_info['temp']}°F. Humidity is {weather_info['humidity']}. Dress accordingly!\",\n",
    "        f\"Here's the weather in {location.title()}: {weather_info['temp']}°F and {weather_info['condition'].lower()}. Humidity levels at {weather_info['humidity']}. Have a great day!\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "def search_knowledge(query):\n",
    "    \"\"\"Enhanced knowledge search with actual information snippets\"\"\"\n",
    "    knowledge_base = {\n",
    "        \"quantum computing\": \"Quantum computing uses quantum bits (qubits) that can exist in multiple states simultaneously, enabling them to solve certain problems much faster than classical computers. Key players include IBM, Google, and Microsoft in developing practical quantum systems.\",\n",
    "        \n",
    "        \"artificial intelligence\": \"AI refers to machines designed to perform tasks that typically require human intelligence. This includes machine learning, natural language processing, computer vision, and robotics. Current trends focus on deep learning and generative AI.\",\n",
    "        \n",
    "        \"renewable energy\": \"Renewable energy comes from natural sources that replenish faster than consumed. Main types include solar, wind, hydroelectric, geothermal, and biomass. Solar and wind have seen rapid cost reductions making them competitive with fossil fuels.\",\n",
    "        \n",
    "        \"blockchain technology\": \"Blockchain is a decentralized digital ledger that records transactions across many computers. It's the technology behind cryptocurrencies like Bitcoin and enables smart contracts, NFTs, and decentralized applications.\",\n",
    "        \n",
    "        \"machine learning\": \"Machine learning is a subset of AI where algorithms improve automatically through experience. Common approaches include supervised learning, unsupervised learning, and reinforcement learning using neural networks and other models.\"\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    for topic, info in knowledge_base.items():\n",
    "        if topic in query_lower:\n",
    "            responses = [\n",
    "                f\"Here's what I know about {topic}: {info}\",\n",
    "                f\"Regarding {topic}: {info}\",\n",
    "                f\"Information about {topic}: {info}\"\n",
    "            ]\n",
    "            return random.choice(responses)\n",
    "    \n",
    "    # Generic response for unknown topics\n",
    "    responses = [\n",
    "        f\"I found some information about '{query}'. This appears to be a topic worth exploring further through specialized resources or recent publications.\",\n",
    "        f\"While I don't have detailed specifics about '{query}', I recommend checking authoritative sources for comprehensive information on this subject.\",\n",
    "        f\"For detailed information about '{query}', I suggest consulting specialized databases, academic papers, or recent news articles for the most current insights.\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "def translate_text(text, target_language=\"Spanish\"):\n",
    "    \"\"\"Enhanced translation with common phrases\"\"\"\n",
    "    common_translations = {\n",
    "        \"hello\": {\n",
    "            \"spanish\": \"Hola\", \"french\": \"Bonjour\", \"german\": \"Hallo\", \n",
    "            \"italian\": \"Ciao\", \"japanese\": \"Konnichiwa\", \"chinese\": \"Nǐ hǎo\"\n",
    "        },\n",
    "        \"thank you\": {\n",
    "            \"spanish\": \"Gracias\", \"french\": \"Merci\", \"german\": \"Danke\",\n",
    "            \"italian\": \"Grazie\", \"japanese\": \"Arigatō\", \"chinese\": \"Xièxiè\"\n",
    "        },\n",
    "        \"how are you\": {\n",
    "            \"spanish\": \"¿Cómo estás?\", \"french\": \"Comment allez-vous?\", \n",
    "            \"german\": \"Wie geht es dir?\", \"italian\": \"Come stai?\",\n",
    "            \"japanese\": \"Ogenki desu ka?\", \"chinese\": \"Nǐ hǎo ma?\"\n",
    "        },\n",
    "        \"goodbye\": {\n",
    "            \"spanish\": \"Adiós\", \"french\": \"Au revoir\", \"german\": \"Auf Wiedersehen\",\n",
    "            \"italian\": \"Arrivederci\", \"japanese\": \"Sayōnara\", \"chinese\": \"Zàijiàn\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    text_lower = text.lower().replace('how do you say', '').replace('in', '').strip(\"? '\")\n",
    "    target_lower = target_language.lower()\n",
    "    \n",
    "    for phrase, translations in common_translations.items():\n",
    "        if phrase in text_lower:\n",
    "            if target_lower in translations:\n",
    "                translation = translations[target_lower]\n",
    "                responses = [\n",
    "                    f\"The translation of '{phrase}' to {target_language} is: '{translation}'\",\n",
    "                    f\"In {target_language}, '{phrase}' is said as: '{translation}'\",\n",
    "                    f\"'{phrase}' translates to '{translation}' in {target_language}\"\n",
    "                ]\n",
    "                return random.choice(responses)\n",
    "    \n",
    "    # Generic translation response\n",
    "    responses = [\n",
    "        f\"For accurate translation of '{text}' to {target_language}, I recommend using dedicated translation services like Google Translate or DeepL for precise results.\",\n",
    "        f\"While I can help with common phrases, for '{text}' in {target_language}, specialized translation tools will provide the most accurate conversion.\",\n",
    "        f\"Translation of '{text}' to {target_language} is best handled by professional translation services to ensure contextual accuracy.\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "def get_current_time(location):\n",
    "    \"\"\"New tool: Get current time for different locations\"\"\"\n",
    "    time_zones = {\n",
    "        \"new york\": -4, \"london\": 1, \"tokyo\": 9, \"paris\": 2,\n",
    "        \"sydney\": 11, \"dubai\": 4, \"los angeles\": -7, \"chicago\": -5\n",
    "    }\n",
    "    \n",
    "    location_lower = location.lower()\n",
    "    for loc, offset in time_zones.items():\n",
    "        if loc in location_lower:\n",
    "            # Simulate time calculation\n",
    "            from datetime import datetime, timedelta\n",
    "            current_time = datetime.utcnow() + timedelta(hours=offset)\n",
    "            time_str = current_time.strftime(\"%I:%M %p\")\n",
    "            \n",
    "            responses = [\n",
    "                f\"Current time in {location.title()}: {time_str}\",\n",
    "                f\"The time in {location.title()} is now {time_str}\",\n",
    "                f\"In {location.title()}, it's currently {time_str}\"\n",
    "            ]\n",
    "            return random.choice(responses)\n",
    "    \n",
    "    return f\" I don't have timezone data for {location}, but you can check world clock websites for accurate time information.\"\n",
    "\n",
    "# Enhanced tool selection classifier\n",
    "tool_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Analyze the user's request and classify which tool to use. Choose from:\n",
    "- math: for calculations, math problems, arithmetic\n",
    "- weather: for weather inquiries, temperature, climate\n",
    "- knowledge: for general information searches, facts, explanations\n",
    "- translate: for language translation, how to say phrases\n",
    "- time: for current time, time zones, what time is it\n",
    "- unknown: if no tool matches\n",
    "\n",
    "Examples:\n",
    "- \"What's 15 * 24?\" → math\n",
    "- \"Weather in London\" → weather  \n",
    "- \"Tell me about AI\" → knowledge\n",
    "- \"How to say hello in French\" → translate\n",
    "- \"What time is it in Tokyo\" → time\n",
    "\n",
    "Request: {request}\n",
    "\n",
    "Respond with only the tool name:\n",
    "\"\"\")\n",
    "\n",
    "tool_chain = tool_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Enhanced tool routing logic\n",
    "def route_to_tool(data):\n",
    "    request = data[\"request\"]\n",
    "    tool = tool_chain.invoke({\"request\": request}).strip().lower()\n",
    "    \n",
    "    print(f\"Selected tool: {tool}\")\n",
    "    \n",
    "    # Enhanced tool execution with better context\n",
    "    if \"math\" in tool:\n",
    "        return calculate_math(request)\n",
    "    elif \"weather\" in tool:\n",
    "        # Extract location from request\n",
    "        location = request.lower().replace('weather', '').replace('in', '').strip()\n",
    "        return get_weather(location if location else \"your location\")\n",
    "    elif \"knowledge\" in tool:\n",
    "        return search_knowledge(request)\n",
    "    elif \"translate\" in tool:\n",
    "        # Extract target language\n",
    "        languages = [\"spanish\", \"french\", \"german\", \"italian\", \"japanese\", \"chinese\"]\n",
    "        target_lang = \"Spanish\"  # default\n",
    "        for lang in languages:\n",
    "            if lang in request.lower():\n",
    "                target_lang = lang.title()\n",
    "                break\n",
    "        return translate_text(request, target_lang)\n",
    "    elif \"time\" in tool:\n",
    "        # Extract location from time request\n",
    "        location = request.lower().replace('time', '').replace('what', '').replace('in', '').strip()\n",
    "        return get_current_time(location if location else \"your location\")\n",
    "    else:\n",
    "        helpful_responses = [\n",
    "            f\"I can help you with: calculations, weather information, general knowledge, translations, and time queries. Your request '{request}' doesn't match my current capabilities perfectly, but I'd be happy to help with related topics!\",\n",
    "            f\"I specialize in math, weather, knowledge searches, translations, and time information. For '{request}', maybe try rephrasing or ask about one of these areas?\",\n",
    "            f\"My expertise includes: mathematical calculations, weather updates, factual information, language translation, and time zones. How can I assist you within these domains?\"\n",
    "        ]\n",
    "        return random.choice(helpful_responses)\n",
    "\n",
    "# Create the enhanced dynamic tool selection chain\n",
    "tool_selection_chain = RunnableLambda(\n",
    "    lambda x: {\"request\": x, \"tool_response\": route_to_tool({\"request\": x})}\n",
    ") | RunnableLambda(lambda x: x[\"tool_response\"])\n",
    "\n",
    "# Test with diverse and realistic requests\n",
    "print(\"ENHANCED TOOL SELECTION SYSTEM\")\n",
    "\n",
    "requests = [\n",
    "    \"What's 15 * 24 + 8?\",\n",
    "    \"What's the weather in New York?\",\n",
    "    \"Tell me about quantum computing\"\n",
    "    # \"How do you say 'thank you' in French?\",\n",
    "    # \"What time is it in Tokyo?\",\n",
    "    # \"Calculate 45 divided by 9\",\n",
    "    # \"What's the temperature in London?\",\n",
    "    # \"Explain artificial intelligence\",\n",
    "    # \"Translate 'hello' to Japanese\",\n",
    "    # \"What's the current time in Paris?\",\n",
    "    # \"Can you help me with my homework?\",\n",
    "    # \"What's 100 minus 25?\"\n",
    "]\n",
    "\n",
    "print(f\"Testing {len(requests)} different requests...\\n\")\n",
    "\n",
    "for i, request in enumerate(requests, 1):\n",
    "    print(f\"#{i}: {request}\")\n",
    "    print(\"─\" * 50)\n",
    "    try:\n",
    "        response = tool_selection_chain.invoke(request)\n",
    "        print(f\"{response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\n\")\n",
    "\n",
    "print(\"Tool selection testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06afa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
